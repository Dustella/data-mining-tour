{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据预处理\n",
    "\n",
    "### 查看数据头部、分割数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>feature0</th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>...</th>\n",
       "      <th>feature97</th>\n",
       "      <th>feature98</th>\n",
       "      <th>feature99</th>\n",
       "      <th>feature100</th>\n",
       "      <th>feature101</th>\n",
       "      <th>feature102</th>\n",
       "      <th>feature103</th>\n",
       "      <th>feature104</th>\n",
       "      <th>feature105</th>\n",
       "      <th>feature106</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>51.567250</td>\n",
       "      <td>288358.400000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.855900</td>\n",
       "      <td>201.460169</td>\n",
       "      <td>6.582261</td>\n",
       "      <td>-0.516321</td>\n",
       "      <td>5.636771e+11</td>\n",
       "      <td>2.222212e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.701891</td>\n",
       "      <td>3.145963e+04</td>\n",
       "      <td>254.582034</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.014506e+08</td>\n",
       "      <td>159.299350</td>\n",
       "      <td>0.603211</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-5.256075</td>\n",
       "      <td>180.977310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>63.804874</td>\n",
       "      <td>288358.400000</td>\n",
       "      <td>1.106802</td>\n",
       "      <td>1.050387</td>\n",
       "      <td>391.605375</td>\n",
       "      <td>13.323439</td>\n",
       "      <td>4.662871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.442474e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.959940</td>\n",
       "      <td>4.283053e+04</td>\n",
       "      <td>270.580779</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.534970e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.506220</td>\n",
       "      <td>0.552654</td>\n",
       "      <td>16.505952</td>\n",
       "      <td>314.783263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>49.138527</td>\n",
       "      <td>288358.400000</td>\n",
       "      <td>1.111649</td>\n",
       "      <td>0.767127</td>\n",
       "      <td>130.708067</td>\n",
       "      <td>6.485547</td>\n",
       "      <td>5.696815</td>\n",
       "      <td>5.474603e+11</td>\n",
       "      <td>-4.288403e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>32.159667</td>\n",
       "      <td>2.499632e+05</td>\n",
       "      <td>160.207067</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.998345e+08</td>\n",
       "      <td>112.632639</td>\n",
       "      <td>0.080100</td>\n",
       "      <td>0.235920</td>\n",
       "      <td>64.707581</td>\n",
       "      <td>183.304610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>288358.400000</td>\n",
       "      <td>1.109169</td>\n",
       "      <td>NaN</td>\n",
       "      <td>258.521076</td>\n",
       "      <td>0.716737</td>\n",
       "      <td>23.238461</td>\n",
       "      <td>-3.539891e+11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.815809</td>\n",
       "      <td>1.254783e+05</td>\n",
       "      <td>196.223295</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.246920e+07</td>\n",
       "      <td>138.431470</td>\n",
       "      <td>2.548783</td>\n",
       "      <td>1.414810</td>\n",
       "      <td>-9.662399</td>\n",
       "      <td>212.302670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>76.520831</td>\n",
       "      <td>288358.400000</td>\n",
       "      <td>1.113410</td>\n",
       "      <td>5.795408</td>\n",
       "      <td>256.038997</td>\n",
       "      <td>-1.803483</td>\n",
       "      <td>14.040495</td>\n",
       "      <td>-1.071014e+11</td>\n",
       "      <td>6.499723e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>40.623904</td>\n",
       "      <td>1.862664e+05</td>\n",
       "      <td>179.083883</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.796351e+08</td>\n",
       "      <td>259.858740</td>\n",
       "      <td>0.337643</td>\n",
       "      <td>0.228832</td>\n",
       "      <td>59.733069</td>\n",
       "      <td>135.541233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6291</th>\n",
       "      <td>6291</td>\n",
       "      <td>70.406112</td>\n",
       "      <td>288358.400000</td>\n",
       "      <td>1.098904</td>\n",
       "      <td>0.134016</td>\n",
       "      <td>222.782078</td>\n",
       "      <td>8.751254</td>\n",
       "      <td>21.783621</td>\n",
       "      <td>-9.018455e+11</td>\n",
       "      <td>-4.047841e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>6.196076</td>\n",
       "      <td>5.235188e+04</td>\n",
       "      <td>217.577771</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.042319e+06</td>\n",
       "      <td>203.750885</td>\n",
       "      <td>0.102876</td>\n",
       "      <td>2.385235</td>\n",
       "      <td>-3.557545</td>\n",
       "      <td>154.955008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6292</th>\n",
       "      <td>6292</td>\n",
       "      <td>72.795989</td>\n",
       "      <td>288358.400000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.503558</td>\n",
       "      <td>408.101229</td>\n",
       "      <td>22.436609</td>\n",
       "      <td>5.631515</td>\n",
       "      <td>-2.376201e+11</td>\n",
       "      <td>-4.051203e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>15.013753</td>\n",
       "      <td>NaN</td>\n",
       "      <td>178.635641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.529909e+08</td>\n",
       "      <td>162.268924</td>\n",
       "      <td>0.824727</td>\n",
       "      <td>1.279274</td>\n",
       "      <td>-8.085779</td>\n",
       "      <td>231.487352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6293</th>\n",
       "      <td>6293</td>\n",
       "      <td>71.210154</td>\n",
       "      <td>515352.218703</td>\n",
       "      <td>2.101946</td>\n",
       "      <td>13.816881</td>\n",
       "      <td>-78.826173</td>\n",
       "      <td>111.744022</td>\n",
       "      <td>50.800576</td>\n",
       "      <td>5.065975e+12</td>\n",
       "      <td>4.996345e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>95.670057</td>\n",
       "      <td>1.662894e+06</td>\n",
       "      <td>-76.537164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.378573e+08</td>\n",
       "      <td>137.228629</td>\n",
       "      <td>12.985847</td>\n",
       "      <td>0.143317</td>\n",
       "      <td>139.819816</td>\n",
       "      <td>-103.883245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6294</th>\n",
       "      <td>6294</td>\n",
       "      <td>NaN</td>\n",
       "      <td>288358.400000</td>\n",
       "      <td>1.106200</td>\n",
       "      <td>1.001885</td>\n",
       "      <td>218.883538</td>\n",
       "      <td>9.064199</td>\n",
       "      <td>9.285105</td>\n",
       "      <td>-2.020482e+10</td>\n",
       "      <td>-1.285311e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.409403</td>\n",
       "      <td>7.515669e+04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.383887e+08</td>\n",
       "      <td>199.620984</td>\n",
       "      <td>0.476171</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-30.718727</td>\n",
       "      <td>183.050026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6295</th>\n",
       "      <td>6295</td>\n",
       "      <td>37.408452</td>\n",
       "      <td>288358.400000</td>\n",
       "      <td>1.101254</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.875245</td>\n",
       "      <td>9.159279</td>\n",
       "      <td>-1.218270</td>\n",
       "      <td>-4.647698e+11</td>\n",
       "      <td>6.104908e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>3.858400</td>\n",
       "      <td>3.812138e+04</td>\n",
       "      <td>291.144747</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.365031e+08</td>\n",
       "      <td>255.460715</td>\n",
       "      <td>0.513641</td>\n",
       "      <td>2.563858</td>\n",
       "      <td>-13.845655</td>\n",
       "      <td>284.550988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6296 rows × 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sample_id   feature0       feature1  feature2   feature3    feature4  \\\n",
       "0             0  51.567250  288358.400000       NaN   1.855900  201.460169   \n",
       "1             1  63.804874  288358.400000  1.106802   1.050387  391.605375   \n",
       "2             2  49.138527  288358.400000  1.111649   0.767127  130.708067   \n",
       "3             3        NaN  288358.400000  1.109169        NaN  258.521076   \n",
       "4             4  76.520831  288358.400000  1.113410   5.795408  256.038997   \n",
       "...         ...        ...            ...       ...        ...         ...   \n",
       "6291       6291  70.406112  288358.400000  1.098904   0.134016  222.782078   \n",
       "6292       6292  72.795989  288358.400000       NaN   0.503558  408.101229   \n",
       "6293       6293  71.210154  515352.218703  2.101946  13.816881  -78.826173   \n",
       "6294       6294        NaN  288358.400000  1.106200   1.001885  218.883538   \n",
       "6295       6295  37.408452  288358.400000  1.101254        NaN   99.875245   \n",
       "\n",
       "        feature5   feature6      feature7      feature8  ...  feature97  \\\n",
       "0       6.582261  -0.516321  5.636771e+11  2.222212e+05  ... -14.701891   \n",
       "1      13.323439   4.662871           NaN -1.442474e+05  ...  -8.959940   \n",
       "2       6.485547   5.696815  5.474603e+11 -4.288403e+05  ...  32.159667   \n",
       "3       0.716737  23.238461 -3.539891e+11           NaN  ...   1.815809   \n",
       "4      -1.803483  14.040495 -1.071014e+11  6.499723e+05  ...  40.623904   \n",
       "...          ...        ...           ...           ...  ...        ...   \n",
       "6291    8.751254  21.783621 -9.018455e+11 -4.047841e+05  ...   6.196076   \n",
       "6292   22.436609   5.631515 -2.376201e+11 -4.051203e+05  ...  15.013753   \n",
       "6293  111.744022  50.800576  5.065975e+12  4.996345e+06  ...  95.670057   \n",
       "6294    9.064199   9.285105 -2.020482e+10 -1.285311e+04  ...  -1.409403   \n",
       "6295    9.159279  -1.218270 -4.647698e+11  6.104908e+04  ...   3.858400   \n",
       "\n",
       "         feature98   feature99  feature100    feature101  feature102  \\\n",
       "0     3.145963e+04  254.582034         0.0 -2.014506e+08  159.299350   \n",
       "1     4.283053e+04  270.580779         0.0 -1.534970e+09         NaN   \n",
       "2     2.499632e+05  160.207067         0.0  7.998345e+08  112.632639   \n",
       "3     1.254783e+05  196.223295         0.0 -9.246920e+07  138.431470   \n",
       "4     1.862664e+05  179.083883         0.0 -6.796351e+08  259.858740   \n",
       "...            ...         ...         ...           ...         ...   \n",
       "6291  5.235188e+04  217.577771         0.0 -9.042319e+06  203.750885   \n",
       "6292           NaN  178.635641         0.0  3.529909e+08  162.268924   \n",
       "6293  1.662894e+06  -76.537164         0.0 -7.378573e+08  137.228629   \n",
       "6294  7.515669e+04         NaN         0.0  3.383887e+08  199.620984   \n",
       "6295  3.812138e+04  291.144747         0.0  5.365031e+08  255.460715   \n",
       "\n",
       "      feature103  feature104  feature105  feature106  \n",
       "0       0.603211         NaN   -5.256075  180.977310  \n",
       "1       0.506220    0.552654   16.505952  314.783263  \n",
       "2       0.080100    0.235920   64.707581  183.304610  \n",
       "3       2.548783    1.414810   -9.662399  212.302670  \n",
       "4       0.337643    0.228832   59.733069  135.541233  \n",
       "...          ...         ...         ...         ...  \n",
       "6291    0.102876    2.385235   -3.557545  154.955008  \n",
       "6292    0.824727    1.279274   -8.085779  231.487352  \n",
       "6293   12.985847    0.143317  139.819816 -103.883245  \n",
       "6294    0.476171         NaN  -30.718727  183.050026  \n",
       "6295    0.513641    2.563858  -13.845655  284.550988  \n",
       "\n",
       "[6296 rows x 108 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv(\"preprocess_train.csv\")\n",
    "# data.head()\n",
    "\n",
    "# 分割数据集\n",
    "\n",
    "X = data.drop(['label'], axis=1)\n",
    "Y = data['label']\n",
    "\n",
    "X"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 补充缺失数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 1.73140199e-01, 6.01641926e-01, ...,\n",
       "        2.03489255e-01, 2.11993579e-01, 1.66942976e-01],\n",
       "       [1.58856235e-04, 1.97690145e-01, 6.01641926e-01, ...,\n",
       "        1.81246419e-01, 2.83081473e-01, 2.45360165e-01],\n",
       "       [3.17712470e-04, 1.68267928e-01, 6.01641926e-01, ...,\n",
       "        1.66114747e-01, 4.40537049e-01, 1.68306894e-01],\n",
       "       ...,\n",
       "       [9.99682288e-01, 2.12545906e-01, 7.59664277e-01, ...,\n",
       "        1.61690724e-01, 6.85898878e-01, 0.00000000e+00],\n",
       "       [9.99841144e-01, 2.01971836e-01, 6.01641926e-01, ...,\n",
       "        2.14021613e-01, 1.28817208e-01, 1.68157694e-01],\n",
       "       [1.00000000e+00, 1.44736179e-01, 6.01641926e-01, ...,\n",
       "        2.77329888e-01, 1.83934833e-01, 2.27642493e-01]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 补充 X 中的缺失值\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=5,missing_values=np.nan)\n",
    "X = imputer.fit_transform(X)\n",
    "\n",
    "# 归一化\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 分割数据集\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "决策树分类器的准确率为：0.78\n",
      "决策树分类器的精确率为：0.75\n",
      "决策树分类器的召回率为：0.76\n",
      "决策树分类器的F1值为：0.76\n"
     ]
    }
   ],
   "source": [
    "# 创建决策树分类器\n",
    "\n",
    "from sklearn.metrics import RocCurveDisplay, accuracy_score, f1_score, precision_score, recall_score, roc_curve\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "tree_clf = DecisionTreeClassifier()\n",
    "# 训练决策树分类器\n",
    "tree_clf.fit(X_train, y_train)\n",
    "# 在测试集上进行预测\n",
    "tree_pred = tree_clf.predict(X_test)\n",
    "# 计算预测准确率\n",
    "tree_acc = accuracy_score(y_test, tree_pred)\n",
    "tree_precision = precision_score(y_test, tree_pred, average='macro')\n",
    "tree_recall = recall_score(y_test, tree_pred, average='macro')\n",
    "tree_f1 = f1_score(y_test, tree_pred, average='macro')\n",
    "print(f\"决策树分类器的准确率为：{tree_acc:.2f}\")\n",
    "print(f\"决策树分类器的精确率为：{tree_precision:.2f}\")\n",
    "print(f\"决策树分类器的召回率为：{tree_recall:.2f}\")\n",
    "print(f\"决策树分类器的F1值为：{tree_f1:.2f}\") \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K近邻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-近邻分类器的准确率为：0.62\n",
      "k-近邻分类器的精确率为：0.62\n",
      "k-近邻分类器的召回率为：0.40\n",
      "k-近邻分类器的F1值为：0.45\n"
     ]
    }
   ],
   "source": [
    "# 创建k-近邻分类器\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "knn_clf = KNeighborsClassifier()\n",
    "# 训练k-近邻分类器\n",
    "knn_clf.fit(X_train, y_train)\n",
    "# 在测试集上进行预测\n",
    "knn_pred = knn_clf.predict(X_test)\n",
    "# 计算预测准确率\n",
    "knn_acc = accuracy_score(y_test, knn_pred)\n",
    "knn_presicion = precision_score(y_test, knn_pred, average='macro')\n",
    "knn_recall = recall_score(y_test, knn_pred, average='macro')\n",
    "knn_f1 = f1_score(y_test, knn_pred, average='macro')\n",
    "\n",
    "print(f\"k-近邻分类器的准确率为：{knn_acc:.2f}\")\n",
    "print(f\"k-近邻分类器的精确率为：{knn_presicion:.2f}\")\n",
    "print(f\"k-近邻分类器的召回率为：{knn_recall:.2f}\")\n",
    "print(f\"k-近邻分类器的F1值为：{knn_f1:.2f}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 逻辑回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "逻辑回归分类器的准确率为：0.73\n",
      "逻辑回归分类器的精确率为：0.84\n",
      "逻辑回归分类器的召回率为：0.56\n",
      "逻辑回归分类器的F1值为：0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dustella\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# 创建逻辑回归分类器\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "logistic_clf = LogisticRegression()\n",
    "# 训练逻辑回归分类器\n",
    "logistic_clf.fit(X_train, y_train)\n",
    "# 在测试集上进行预测\n",
    "logistic_pred = logistic_clf.predict(X_test)\n",
    "# 计算预测准确率\n",
    "logistic_acc = accuracy_score(y_test, logistic_pred)\n",
    "logistic_presicion = precision_score(y_test, logistic_pred, average='macro')\n",
    "logistic_recall = recall_score(y_test, logistic_pred, average='macro')\n",
    "logistic_f1 = f1_score(y_test, logistic_pred, average='macro')\n",
    "\n",
    "print(f\"逻辑回归分类器的准确率为：{logistic_acc:.2f}\")\n",
    "print(f\"逻辑回归分类器的精确率为：{logistic_presicion:.2f}\")\n",
    "print(f\"逻辑回归分类器的召回率为：{logistic_recall:.2f}\")\n",
    "print(f\"逻辑回归分类器的F1值为：{logistic_f1:.2f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 支持向量机"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM分类器的准确率为：0.76\n",
      "SVM分类器的精确率为：0.87\n",
      "SVM分类器的召回率为：0.60\n",
      "SVM分类器的F1值为：0.65\n"
     ]
    }
   ],
   "source": [
    "# 创建SVM分类器\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "svm_clf = SVC()\n",
    "# 训练SVM分类器\n",
    "svm_clf.fit(X_train, y_train)\n",
    "# 在测试集上进行预测\n",
    "svm_pred = svm_clf.predict(X_test)\n",
    "# 计算预测准确率\n",
    "svm_acc = accuracy_score(y_test, svm_pred)\n",
    "svm_presicion = precision_score(y_test, svm_pred, average='macro')\n",
    "svm_recall = recall_score(y_test, svm_pred, average='macro')\n",
    "svm_f1 = f1_score(y_test, svm_pred, average='macro')\n",
    "\n",
    "print(f\"SVM分类器的准确率为：{svm_acc:.2f}\")\n",
    "print(f\"SVM分类器的精确率为：{svm_presicion:.2f}\")\n",
    "print(f\"SVM分类器的召回率为：{svm_recall:.2f}\")\n",
    "print(f\"SVM分类器的F1值为：{svm_f1:.2f}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost分类器的准确率为：0.64\n",
      "Adaboost分类器的精确率为：0.64\n",
      "Adaboost分类器的召回率为：0.66\n",
      "Adaboost分类器的F1值为：0.64\n"
     ]
    }
   ],
   "source": [
    "# 创建Adaboost分类器\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "\n",
    "adaboost_clf = AdaBoostClassifier()\n",
    "# 训练Adaboost分类器\n",
    "adaboost_clf.fit(X_train, y_train)\n",
    "# 在测试集上进行预测\n",
    "adaboost_pred = adaboost_clf.predict(X_test)\n",
    "# 计算预测准确率\n",
    "adaboost_acc = accuracy_score(y_test, adaboost_pred)\n",
    "adaboost_presicion = precision_score(y_test, adaboost_pred, average='macro')\n",
    "adaboost_recall = recall_score(y_test, adaboost_pred, average='macro')\n",
    "adaboost_f1 = f1_score(y_test, adaboost_pred, average='macro')\n",
    "\n",
    "print(f\"Adaboost分类器的准确率为：{adaboost_acc:.2f}\")\n",
    "print(f\"Adaboost分类器的精确率为：{adaboost_presicion:.2f}\")\n",
    "print(f\"Adaboost分类器的召回率为：{adaboost_recall:.2f}\")\n",
    "print(f\"Adaboost分类器的F1值为：{adaboost_f1:.2f}\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 随机森林"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "随机森林分类器的准确率为：0.85\n",
      "随机森林分类器的精确率为：0.88\n",
      "随机森林分类器的召回率为：0.77\n",
      "随机森林分类器的F1值为：0.82\n"
     ]
    }
   ],
   "source": [
    "# 创建随机森林分类器\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "rf_clf = RandomForestClassifier()\n",
    "# 训练随机森林分类器\n",
    "rf_clf.fit(X_train, y_train)\n",
    "# 在测试集上进行预测\n",
    "rf_pred = rf_clf.predict(X_test)\n",
    "# 计算预测准确率\n",
    "rf_acc = accuracy_score(y_test, rf_pred)\n",
    "rf_presicion = precision_score(y_test, rf_pred, average='macro')\n",
    "rf_recall = recall_score(y_test, rf_pred, average='macro')\n",
    "rf_f1 = f1_score(y_test, rf_pred, average='macro')\n",
    "\n",
    "print(f\"随机森林分类器的准确率为：{rf_acc:.2f}\")\n",
    "print(f\"随机森林分类器的精确率为：{rf_presicion:.2f}\")\n",
    "print(f\"随机森林分类器的召回率为：{rf_recall:.2f}\")\n",
    "print(f\"随机森林分类器的F1值为：{rf_f1:.2f}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 投票"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "投票分类器的准确率为：0.67\n",
      "投票分类器的精确率为：0.89\n",
      "投票分类器的召回率为：0.43\n",
      "投票分类器的F1值为：0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dustella\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# 创建决策树、k-近邻和逻辑回归分类器\n",
    "tree_clf = DecisionTreeClassifier(max_depth=3)\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=3)\n",
    "logistic_clf = LogisticRegression()\n",
    "\n",
    "# 创建投票分类器\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('tree', tree_clf), ('knn', knn_clf),\n",
    "                ('logistic', logistic_clf)],\n",
    "    voting='hard'\n",
    ")\n",
    "\n",
    "# 训练投票分类器\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# 在测试集上进行预测\n",
    "voting_pred = voting_clf.predict(X_test)\n",
    "# 计算预测准确率\n",
    "voting_acc = accuracy_score(y_test, voting_pred)\n",
    "voting_presicion = precision_score(y_test, voting_pred, average='macro')\n",
    "voting_recall = recall_score(y_test, voting_pred, average='macro')\n",
    "voting_f1 = f1_score(y_test, voting_pred, average='macro')\n",
    "print(f\"投票分类器的准确率为：{voting_acc:.2f}\")\n",
    "print(f\"投票分类器的精确率为：{voting_presicion:.2f}\")\n",
    "print(f\"投票分类器的召回率为：{voting_recall:.2f}\")\n",
    "print(f\"投票分类器的F1值为：{voting_f1:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 画出所有分类器的 准确率、精确率、召回率、F1值 的柱状图\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 准确率\n",
    "acc = [tree_acc, knn_acc, logistic_acc, svm_acc, adaboost_acc, rf_acc, voting_acc]\n",
    "# 精确率\n",
    "presicion = [tree_precision, knn_presicion, logistic_presicion, svm_presicion, adaboost_presicion, rf_presicion, voting_presicion]\n",
    "# 召回率\n",
    "recall = [tree_recall, knn_recall, logistic_recall, svm_recall, adaboost_recall, rf_recall, voting_recall]\n",
    "# F1值\n",
    "f1 = [tree_f1, knn_f1, logistic_f1, svm_f1, adaboost_f1, rf_f1, voting_f1]\n",
    "\n",
    "# 柱状图的标签\n",
    "labels = ['DecisionTree', 'KNN', 'Logistic', 'SVM', 'Adaboost', 'RandomForest', 'Voting']\n",
    "\n",
    "# 柱状图的位置\n",
    "x = np.arange(len(labels))\n",
    "\n",
    "# 柱状图的宽度\n",
    "width = 0.2\n",
    "\n",
    "# 画出准确率的柱状图\n",
    "plt.bar(x, acc, width, label='acc')\n",
    "# 画出精确率的柱状图\n",
    "plt.bar(x + width, presicion, width, label='presicion')\n",
    "# 画出召回率的柱状图\n",
    "plt.bar(x + 2 * width, recall, width, label='recall')\n",
    "# 画出F1值的柱状图\n",
    "plt.bar(x + 3 * width, f1, width, label='f1')\n",
    "\n",
    "# 设置柱状图的标签\n",
    "plt.xticks(x + width, labels)\n",
    "\n",
    "# 设置图例\n",
    "plt.legend()\n",
    "\n",
    "# 显示图像\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
