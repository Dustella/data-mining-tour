{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据预处理\n",
    "\n",
    "### 查看数据头部、分割数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>feature0</th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>...</th>\n",
       "      <th>feature97</th>\n",
       "      <th>feature98</th>\n",
       "      <th>feature99</th>\n",
       "      <th>feature100</th>\n",
       "      <th>feature101</th>\n",
       "      <th>feature102</th>\n",
       "      <th>feature103</th>\n",
       "      <th>feature104</th>\n",
       "      <th>feature105</th>\n",
       "      <th>feature106</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>51.567250</td>\n",
       "      <td>288358.400000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.855900</td>\n",
       "      <td>201.460169</td>\n",
       "      <td>6.582261</td>\n",
       "      <td>-0.516321</td>\n",
       "      <td>5.636771e+11</td>\n",
       "      <td>2.222212e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.701891</td>\n",
       "      <td>3.145963e+04</td>\n",
       "      <td>254.582034</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.014506e+08</td>\n",
       "      <td>159.299350</td>\n",
       "      <td>0.603211</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-5.256075</td>\n",
       "      <td>180.977310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>63.804874</td>\n",
       "      <td>288358.400000</td>\n",
       "      <td>1.106802</td>\n",
       "      <td>1.050387</td>\n",
       "      <td>391.605375</td>\n",
       "      <td>13.323439</td>\n",
       "      <td>4.662871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.442474e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.959940</td>\n",
       "      <td>4.283053e+04</td>\n",
       "      <td>270.580779</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.534970e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.506220</td>\n",
       "      <td>0.552654</td>\n",
       "      <td>16.505952</td>\n",
       "      <td>314.783263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>49.138527</td>\n",
       "      <td>288358.400000</td>\n",
       "      <td>1.111649</td>\n",
       "      <td>0.767127</td>\n",
       "      <td>130.708067</td>\n",
       "      <td>6.485547</td>\n",
       "      <td>5.696815</td>\n",
       "      <td>5.474603e+11</td>\n",
       "      <td>-4.288403e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>32.159667</td>\n",
       "      <td>2.499632e+05</td>\n",
       "      <td>160.207067</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.998345e+08</td>\n",
       "      <td>112.632639</td>\n",
       "      <td>0.080100</td>\n",
       "      <td>0.235920</td>\n",
       "      <td>64.707581</td>\n",
       "      <td>183.304610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>288358.400000</td>\n",
       "      <td>1.109169</td>\n",
       "      <td>NaN</td>\n",
       "      <td>258.521076</td>\n",
       "      <td>0.716737</td>\n",
       "      <td>23.238461</td>\n",
       "      <td>-3.539891e+11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.815809</td>\n",
       "      <td>1.254783e+05</td>\n",
       "      <td>196.223295</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.246920e+07</td>\n",
       "      <td>138.431470</td>\n",
       "      <td>2.548783</td>\n",
       "      <td>1.414810</td>\n",
       "      <td>-9.662399</td>\n",
       "      <td>212.302670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>76.520831</td>\n",
       "      <td>288358.400000</td>\n",
       "      <td>1.113410</td>\n",
       "      <td>5.795408</td>\n",
       "      <td>256.038997</td>\n",
       "      <td>-1.803483</td>\n",
       "      <td>14.040495</td>\n",
       "      <td>-1.071014e+11</td>\n",
       "      <td>6.499723e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>40.623904</td>\n",
       "      <td>1.862664e+05</td>\n",
       "      <td>179.083883</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.796351e+08</td>\n",
       "      <td>259.858740</td>\n",
       "      <td>0.337643</td>\n",
       "      <td>0.228832</td>\n",
       "      <td>59.733069</td>\n",
       "      <td>135.541233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6291</th>\n",
       "      <td>6291</td>\n",
       "      <td>70.406112</td>\n",
       "      <td>288358.400000</td>\n",
       "      <td>1.098904</td>\n",
       "      <td>0.134016</td>\n",
       "      <td>222.782078</td>\n",
       "      <td>8.751254</td>\n",
       "      <td>21.783621</td>\n",
       "      <td>-9.018455e+11</td>\n",
       "      <td>-4.047841e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>6.196076</td>\n",
       "      <td>5.235188e+04</td>\n",
       "      <td>217.577771</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.042319e+06</td>\n",
       "      <td>203.750885</td>\n",
       "      <td>0.102876</td>\n",
       "      <td>2.385235</td>\n",
       "      <td>-3.557545</td>\n",
       "      <td>154.955008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6292</th>\n",
       "      <td>6292</td>\n",
       "      <td>72.795989</td>\n",
       "      <td>288358.400000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.503558</td>\n",
       "      <td>408.101229</td>\n",
       "      <td>22.436609</td>\n",
       "      <td>5.631515</td>\n",
       "      <td>-2.376201e+11</td>\n",
       "      <td>-4.051203e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>15.013753</td>\n",
       "      <td>NaN</td>\n",
       "      <td>178.635641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.529909e+08</td>\n",
       "      <td>162.268924</td>\n",
       "      <td>0.824727</td>\n",
       "      <td>1.279274</td>\n",
       "      <td>-8.085779</td>\n",
       "      <td>231.487352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6293</th>\n",
       "      <td>6293</td>\n",
       "      <td>71.210154</td>\n",
       "      <td>515352.218703</td>\n",
       "      <td>2.101946</td>\n",
       "      <td>13.816881</td>\n",
       "      <td>-78.826173</td>\n",
       "      <td>111.744022</td>\n",
       "      <td>50.800576</td>\n",
       "      <td>5.065975e+12</td>\n",
       "      <td>4.996345e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>95.670057</td>\n",
       "      <td>1.662894e+06</td>\n",
       "      <td>-76.537164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.378573e+08</td>\n",
       "      <td>137.228629</td>\n",
       "      <td>12.985847</td>\n",
       "      <td>0.143317</td>\n",
       "      <td>139.819816</td>\n",
       "      <td>-103.883245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6294</th>\n",
       "      <td>6294</td>\n",
       "      <td>NaN</td>\n",
       "      <td>288358.400000</td>\n",
       "      <td>1.106200</td>\n",
       "      <td>1.001885</td>\n",
       "      <td>218.883538</td>\n",
       "      <td>9.064199</td>\n",
       "      <td>9.285105</td>\n",
       "      <td>-2.020482e+10</td>\n",
       "      <td>-1.285311e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.409403</td>\n",
       "      <td>7.515669e+04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.383887e+08</td>\n",
       "      <td>199.620984</td>\n",
       "      <td>0.476171</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-30.718727</td>\n",
       "      <td>183.050026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6295</th>\n",
       "      <td>6295</td>\n",
       "      <td>37.408452</td>\n",
       "      <td>288358.400000</td>\n",
       "      <td>1.101254</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.875245</td>\n",
       "      <td>9.159279</td>\n",
       "      <td>-1.218270</td>\n",
       "      <td>-4.647698e+11</td>\n",
       "      <td>6.104908e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>3.858400</td>\n",
       "      <td>3.812138e+04</td>\n",
       "      <td>291.144747</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.365031e+08</td>\n",
       "      <td>255.460715</td>\n",
       "      <td>0.513641</td>\n",
       "      <td>2.563858</td>\n",
       "      <td>-13.845655</td>\n",
       "      <td>284.550988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6296 rows × 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sample_id   feature0       feature1  feature2   feature3    feature4   \n",
       "0             0  51.567250  288358.400000       NaN   1.855900  201.460169  \\\n",
       "1             1  63.804874  288358.400000  1.106802   1.050387  391.605375   \n",
       "2             2  49.138527  288358.400000  1.111649   0.767127  130.708067   \n",
       "3             3        NaN  288358.400000  1.109169        NaN  258.521076   \n",
       "4             4  76.520831  288358.400000  1.113410   5.795408  256.038997   \n",
       "...         ...        ...            ...       ...        ...         ...   \n",
       "6291       6291  70.406112  288358.400000  1.098904   0.134016  222.782078   \n",
       "6292       6292  72.795989  288358.400000       NaN   0.503558  408.101229   \n",
       "6293       6293  71.210154  515352.218703  2.101946  13.816881  -78.826173   \n",
       "6294       6294        NaN  288358.400000  1.106200   1.001885  218.883538   \n",
       "6295       6295  37.408452  288358.400000  1.101254        NaN   99.875245   \n",
       "\n",
       "        feature5   feature6      feature7      feature8  ...  feature97   \n",
       "0       6.582261  -0.516321  5.636771e+11  2.222212e+05  ... -14.701891  \\\n",
       "1      13.323439   4.662871           NaN -1.442474e+05  ...  -8.959940   \n",
       "2       6.485547   5.696815  5.474603e+11 -4.288403e+05  ...  32.159667   \n",
       "3       0.716737  23.238461 -3.539891e+11           NaN  ...   1.815809   \n",
       "4      -1.803483  14.040495 -1.071014e+11  6.499723e+05  ...  40.623904   \n",
       "...          ...        ...           ...           ...  ...        ...   \n",
       "6291    8.751254  21.783621 -9.018455e+11 -4.047841e+05  ...   6.196076   \n",
       "6292   22.436609   5.631515 -2.376201e+11 -4.051203e+05  ...  15.013753   \n",
       "6293  111.744022  50.800576  5.065975e+12  4.996345e+06  ...  95.670057   \n",
       "6294    9.064199   9.285105 -2.020482e+10 -1.285311e+04  ...  -1.409403   \n",
       "6295    9.159279  -1.218270 -4.647698e+11  6.104908e+04  ...   3.858400   \n",
       "\n",
       "         feature98   feature99  feature100    feature101  feature102   \n",
       "0     3.145963e+04  254.582034         0.0 -2.014506e+08  159.299350  \\\n",
       "1     4.283053e+04  270.580779         0.0 -1.534970e+09         NaN   \n",
       "2     2.499632e+05  160.207067         0.0  7.998345e+08  112.632639   \n",
       "3     1.254783e+05  196.223295         0.0 -9.246920e+07  138.431470   \n",
       "4     1.862664e+05  179.083883         0.0 -6.796351e+08  259.858740   \n",
       "...            ...         ...         ...           ...         ...   \n",
       "6291  5.235188e+04  217.577771         0.0 -9.042319e+06  203.750885   \n",
       "6292           NaN  178.635641         0.0  3.529909e+08  162.268924   \n",
       "6293  1.662894e+06  -76.537164         0.0 -7.378573e+08  137.228629   \n",
       "6294  7.515669e+04         NaN         0.0  3.383887e+08  199.620984   \n",
       "6295  3.812138e+04  291.144747         0.0  5.365031e+08  255.460715   \n",
       "\n",
       "      feature103  feature104  feature105  feature106  \n",
       "0       0.603211         NaN   -5.256075  180.977310  \n",
       "1       0.506220    0.552654   16.505952  314.783263  \n",
       "2       0.080100    0.235920   64.707581  183.304610  \n",
       "3       2.548783    1.414810   -9.662399  212.302670  \n",
       "4       0.337643    0.228832   59.733069  135.541233  \n",
       "...          ...         ...         ...         ...  \n",
       "6291    0.102876    2.385235   -3.557545  154.955008  \n",
       "6292    0.824727    1.279274   -8.085779  231.487352  \n",
       "6293   12.985847    0.143317  139.819816 -103.883245  \n",
       "6294    0.476171         NaN  -30.718727  183.050026  \n",
       "6295    0.513641    2.563858  -13.845655  284.550988  \n",
       "\n",
       "[6296 rows x 108 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv(\"preprocess_train.csv\")\n",
    "# data.head()\n",
    "\n",
    "# 分割数据集\n",
    "\n",
    "X = data.drop(['label'], axis=1)\n",
    "Y = data['label']\n",
    "\n",
    "X"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 补充缺失数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 1.73140199e-01, 6.01641926e-01, ...,\n",
       "        2.03489255e-01, 2.11993579e-01, 1.66942976e-01],\n",
       "       [1.58856235e-04, 1.97690145e-01, 6.01641926e-01, ...,\n",
       "        1.81246419e-01, 2.83081473e-01, 2.45360165e-01],\n",
       "       [3.17712470e-04, 1.68267928e-01, 6.01641926e-01, ...,\n",
       "        1.66114747e-01, 4.40537049e-01, 1.68306894e-01],\n",
       "       ...,\n",
       "       [9.99682288e-01, 2.12545906e-01, 7.59664277e-01, ...,\n",
       "        1.61690724e-01, 6.85898878e-01, 0.00000000e+00],\n",
       "       [9.99841144e-01, 2.01971836e-01, 6.01641926e-01, ...,\n",
       "        2.14021613e-01, 1.28817208e-01, 1.68157694e-01],\n",
       "       [1.00000000e+00, 1.44736179e-01, 6.01641926e-01, ...,\n",
       "        2.77329888e-01, 1.83934833e-01, 2.27642493e-01]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 补充 X 中的缺失值\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=5,missing_values=np.nan)\n",
    "X = imputer.fit_transform(X)\n",
    "\n",
    "# 归一化\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 分割数据集\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "决策树分类器的准确率为：0.79\n",
      "决策树分类器的精确率为：0.76\n",
      "决策树分类器的召回率为：0.76\n",
      "决策树分类器的F1值为：0.76\n"
     ]
    }
   ],
   "source": [
    "# 创建决策树分类器\n",
    "\n",
    "from sklearn.metrics import RocCurveDisplay, accuracy_score, f1_score, precision_score, recall_score, roc_curve\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "tree_clf = DecisionTreeClassifier()\n",
    "# 训练决策树分类器\n",
    "tree_clf.fit(X_train, y_train)\n",
    "# 在测试集上进行预测\n",
    "tree_pred = tree_clf.predict(X_test)\n",
    "# 计算预测准确率\n",
    "tree_acc = accuracy_score(y_test, tree_pred)\n",
    "tree_precision = precision_score(y_test, tree_pred, average='macro')\n",
    "tree_recall = recall_score(y_test, tree_pred, average='macro')\n",
    "tree_f1 = f1_score(y_test, tree_pred, average='macro')\n",
    "print(f\"决策树分类器的准确率为：{tree_acc:.2f}\")\n",
    "print(f\"决策树分类器的精确率为：{tree_precision:.2f}\")\n",
    "print(f\"决策树分类器的召回率为：{tree_recall:.2f}\")\n",
    "print(f\"决策树分类器的F1值为：{tree_f1:.2f}\") \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K近邻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-近邻分类器的准确率为：0.62\n",
      "k-近邻分类器的精确率为：0.62\n",
      "k-近邻分类器的召回率为：0.40\n",
      "k-近邻分类器的F1值为：0.45\n"
     ]
    }
   ],
   "source": [
    "# 创建k-近邻分类器\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "knn_clf = KNeighborsClassifier()\n",
    "# 训练k-近邻分类器\n",
    "knn_clf.fit(X_train, y_train)\n",
    "# 在测试集上进行预测\n",
    "knn_pred = knn_clf.predict(X_test)\n",
    "# 计算预测准确率\n",
    "knn_acc = accuracy_score(y_test, knn_pred)\n",
    "knn_presicion = precision_score(y_test, knn_pred, average='macro')\n",
    "knn_recall = recall_score(y_test, knn_pred, average='macro')\n",
    "knn_f1 = f1_score(y_test, knn_pred, average='macro')\n",
    "\n",
    "print(f\"k-近邻分类器的准确率为：{knn_acc:.2f}\")\n",
    "print(f\"k-近邻分类器的精确率为：{knn_presicion:.2f}\")\n",
    "print(f\"k-近邻分类器的召回率为：{knn_recall:.2f}\")\n",
    "print(f\"k-近邻分类器的F1值为：{knn_f1:.2f}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 逻辑回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "逻辑回归分类器的准确率为：0.73\n",
      "逻辑回归分类器的精确率为：0.84\n",
      "逻辑回归分类器的召回率为：0.56\n",
      "逻辑回归分类器的F1值为：0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dustella\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# 创建逻辑回归分类器\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "logistic_clf = LogisticRegression()\n",
    "# 训练逻辑回归分类器\n",
    "logistic_clf.fit(X_train, y_train)\n",
    "# 在测试集上进行预测\n",
    "logistic_pred = logistic_clf.predict(X_test)\n",
    "# 计算预测准确率\n",
    "logistic_acc = accuracy_score(y_test, logistic_pred)\n",
    "logistic_presicion = precision_score(y_test, logistic_pred, average='macro')\n",
    "logistic_recall = recall_score(y_test, logistic_pred, average='macro')\n",
    "logistic_f1 = f1_score(y_test, logistic_pred, average='macro')\n",
    "\n",
    "print(f\"逻辑回归分类器的准确率为：{logistic_acc:.2f}\")\n",
    "print(f\"逻辑回归分类器的精确率为：{logistic_presicion:.2f}\")\n",
    "print(f\"逻辑回归分类器的召回率为：{logistic_recall:.2f}\")\n",
    "print(f\"逻辑回归分类器的F1值为：{logistic_f1:.2f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 支持向量机"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM分类器的准确率为：0.76\n",
      "SVM分类器的精确率为：0.87\n",
      "SVM分类器的召回率为：0.60\n",
      "SVM分类器的F1值为：0.65\n"
     ]
    }
   ],
   "source": [
    "# 创建SVM分类器\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "svm_clf = SVC()\n",
    "# 训练SVM分类器\n",
    "svm_clf.fit(X_train, y_train)\n",
    "# 在测试集上进行预测\n",
    "svm_pred = svm_clf.predict(X_test)\n",
    "# 计算预测准确率\n",
    "svm_acc = accuracy_score(y_test, svm_pred)\n",
    "svm_presicion = precision_score(y_test, svm_pred, average='macro')\n",
    "svm_recall = recall_score(y_test, svm_pred, average='macro')\n",
    "svm_f1 = f1_score(y_test, svm_pred, average='macro')\n",
    "\n",
    "print(f\"SVM分类器的准确率为：{svm_acc:.2f}\")\n",
    "print(f\"SVM分类器的精确率为：{svm_presicion:.2f}\")\n",
    "print(f\"SVM分类器的召回率为：{svm_recall:.2f}\")\n",
    "print(f\"SVM分类器的F1值为：{svm_f1:.2f}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost分类器的准确率为：0.64\n",
      "Adaboost分类器的精确率为：0.64\n",
      "Adaboost分类器的召回率为：0.66\n",
      "Adaboost分类器的F1值为：0.64\n"
     ]
    }
   ],
   "source": [
    "# 创建Adaboost分类器\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "\n",
    "adaboost_clf = AdaBoostClassifier()\n",
    "# 训练Adaboost分类器\n",
    "adaboost_clf.fit(X_train, y_train)\n",
    "# 在测试集上进行预测\n",
    "adaboost_pred = adaboost_clf.predict(X_test)\n",
    "# 计算预测准确率\n",
    "adaboost_acc = accuracy_score(y_test, adaboost_pred)\n",
    "adaboost_presicion = precision_score(y_test, adaboost_pred, average='macro')\n",
    "adaboost_recall = recall_score(y_test, adaboost_pred, average='macro')\n",
    "adaboost_f1 = f1_score(y_test, adaboost_pred, average='macro')\n",
    "\n",
    "print(f\"Adaboost分类器的准确率为：{adaboost_acc:.2f}\")\n",
    "print(f\"Adaboost分类器的精确率为：{adaboost_presicion:.2f}\")\n",
    "print(f\"Adaboost分类器的召回率为：{adaboost_recall:.2f}\")\n",
    "print(f\"Adaboost分类器的F1值为：{adaboost_f1:.2f}\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 随机森林"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "随机森林分类器的准确率为：0.84\n",
      "随机森林分类器的精确率为：0.88\n",
      "随机森林分类器的召回率为：0.76\n",
      "随机森林分类器的F1值为：0.81\n"
     ]
    }
   ],
   "source": [
    "# 创建随机森林分类器\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "rf_clf = RandomForestClassifier()\n",
    "# 训练随机森林分类器\n",
    "rf_clf.fit(X_train, y_train)\n",
    "# 在测试集上进行预测\n",
    "rf_pred = rf_clf.predict(X_test)\n",
    "# 计算预测准确率\n",
    "rf_acc = accuracy_score(y_test, rf_pred)\n",
    "rf_presicion = precision_score(y_test, rf_pred, average='macro')\n",
    "rf_recall = recall_score(y_test, rf_pred, average='macro')\n",
    "rf_f1 = f1_score(y_test, rf_pred, average='macro')\n",
    "\n",
    "print(f\"随机森林分类器的准确率为：{rf_acc:.2f}\")\n",
    "print(f\"随机森林分类器的精确率为：{rf_presicion:.2f}\")\n",
    "print(f\"随机森林分类器的召回率为：{rf_recall:.2f}\")\n",
    "print(f\"随机森林分类器的F1值为：{rf_f1:.2f}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 投票"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "投票分类器的准确率为：0.81\n",
      "投票分类器的精确率为：0.83\n",
      "投票分类器的召回率为：0.74\n",
      "投票分类器的F1值为：0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dustella\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# 创建决策树、k-近邻和逻辑回归分类器\n",
    "tree_clf = DecisionTreeClassifier()\n",
    "knn_clf = KNeighborsClassifier()\n",
    "logistic_clf = LogisticRegression()\n",
    "\n",
    "# 创建投票分类器\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('tree', tree_clf), ('knn', knn_clf),\n",
    "                ('logistic', logistic_clf)],\n",
    "    voting='hard'\n",
    ")\n",
    "\n",
    "# 训练投票分类器\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# 在测试集上进行预测\n",
    "voting_pred = voting_clf.predict(X_test)\n",
    "# 计算预测准确率\n",
    "voting_acc = accuracy_score(y_test, voting_pred)\n",
    "voting_presicion = precision_score(y_test, voting_pred, average='macro')\n",
    "voting_recall = recall_score(y_test, voting_pred, average='macro')\n",
    "voting_f1 = f1_score(y_test, voting_pred, average='macro')\n",
    "print(f\"投票分类器的准确率为：{voting_acc:.2f}\")\n",
    "print(f\"投票分类器的精确率为：{voting_presicion:.2f}\")\n",
    "print(f\"投票分类器的召回率为：{voting_recall:.2f}\")\n",
    "print(f\"投票分类器的F1值为：{voting_f1:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 画出所有分类器的 准确率、精确率、召回率、F1值 的柱状图\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = [tree_acc, knn_acc, logistic_acc, svm_acc, adaboost_acc, rf_acc, voting_acc]\n",
    "presicion = [tree_precision, knn_presicion, logistic_presicion, svm_presicion, adaboost_presicion, rf_presicion, voting_presicion]\n",
    "recall = [tree_recall, knn_recall, logistic_recall, svm_recall, adaboost_recall, rf_recall, voting_recall]\n",
    "f1 = [tree_f1, knn_f1, logistic_f1, svm_f1, adaboost_f1, rf_f1, voting_f1]\n",
    "\n",
    "labels = ['DecisionTree', 'KNN', 'Logistic', 'SVM', 'Adaboost', 'RandomForest', 'Voting']\n",
    "x = np.arange(len(labels))\n",
    "width = 0.2\n",
    "\n",
    "# 画出准确率的柱状图\n",
    "plt.bar(x, acc, width, label='acc')\n",
    "plt.bar(x + width, presicion, width, label='presicion')\n",
    "plt.bar(x + 2 * width, recall, width, label='recall')\n",
    "plt.bar(x + 3 * width, f1, width, label='f1')\n",
    "plt.xticks(x + width, labels)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
